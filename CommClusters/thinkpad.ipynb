{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Clustering Countries Based on Ratings of Women's Rights in the Workplace\n",
    "\n",
    "$$ E_x = BERT(x) \\delta_{w=w'} $$\n",
    "\n",
    "$$ P(E_x|E_y) = P_{\\mathcal{N}_{\\mathcal{T}[0, \\infty]}} \\left( cosineError(E_x, E_y) \\bigg| \\mu=0, \\sigma \\right) $$\n",
    "\n",
    "$$ P(A|B) = \\frac{1}{N} \\left( \\frac{P(E_A|E_B)}{P(E_B|E_B)}  \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CommClusters.mod.context_vecs import *\n",
    "from CommClusters.data.byVar import *\n",
    "\n",
    "VERBOSE=True\n",
    "\n",
    "# VARS = ['polygamy', 'polygyny', 'wife', 'wives', 'polygynous', 'women', 'marriage', 'marriages']\n",
    "VARS = ['polygamy', 'polygyny', 'wife', 'wives', 'women', 'woman']\n",
    "# VARS = ['women', 'attack']\n",
    "\n",
    "OUTDATA_PATH = \"CommClusters/data/corpora/WomanStats/PW/d_PW(p3).csv\"\n",
    "df_out = pd.DataFrame(columns=['country', 'var', 'vec'])\n",
    "df_out.to_csv(OUTDATA_PATH, index=False, encoding='utf-8')\n",
    "for country in df['Country'].unique():\n",
    "    if VERBOSE:\n",
    "        print('{} started'.format(country))\n",
    "    subdata = df['Data'].loc[df['Country'].isin([country])].values\n",
    "    for val in subdata:\n",
    "        for var in VARS:\n",
    "            if var in val.lower():\n",
    "                try:\n",
    "                    data=[[country,var,str(i.view(-1).tolist())] for i in nC(var,val)]\n",
    "                    data = np.array(data).reshape(-1,3)\n",
    "                    data=pd.DataFrame(data,columns=list(df_out))\n",
    "                    data.to_csv(OUTDATA_PATH, index=False, header=False, encoding='utf-8', mode='a')\n",
    "                except ValueError:\n",
    "                    0\n",
    "                except IndexError:\n",
    "                    0\n",
    "    if VERBOSE:\n",
    "        print('=====]{}[====='.format(len(subdata)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up similarity tables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CommClusters.mod.sim_matrix import *\n",
    "\n",
    "NEW = True\n",
    "\n",
    "# input_path = 'CommClusters/data/corpora/WomanStats/LRW/d_LRW.csv'\n",
    "# input_path = 'CommClusters/data/corpora/WomanStats/M/d_M.csv'\n",
    "input_path = 'CommClusters/data/corpora/WomanStats/PW/d_PW(p1).csv'\n",
    "\n",
    "dfi = pd.read_csv(input_path)\n",
    "print(dfi['var'].unique())\n",
    "cID, vID, vecs = dfi['country'].values, dfi['var'].values, torch.FloatTensor([[np.float(i) for i in j.replace('[', '').replace(']', '').split(', ')] for j in dfi['vec'].values])\n",
    "\n",
    "pA = probFn(.3)\n",
    "\n",
    "# vars = ['wives', 'wife']\n",
    "vars = ['polygamy', 'polygyny', #'polygynous'\n",
    "        ]\n",
    "# vars = vars+['marriages', 'marriage']\n",
    "# vars = dfi['var'].unique().tolist()\n",
    "# vars = ['women']\n",
    "\n",
    "cID, vecs = cID[sel(vars, vID)], vecs[sel(vars,vID)]\n",
    "print(np.unique(cID), vecs.shape)\n",
    "\n",
    "matrix_data = []\n",
    "\n",
    "topK = 5\n",
    "\n",
    "c_unique = np.unique(cID)\n",
    "for country in c_unique:\n",
    "    A = vecs[sel([country], cID)]\n",
    "    outputs = []\n",
    "    for C in c_unique:\n",
    "        B = vecs[sel([C], cID)]\n",
    "        res = None\n",
    "        if B.shape[0] >= topK:\n",
    "            res = pA.PROB(A,B).topk(k=topK, dim=1)[0].mean().view(-1) / pA.PROB(B,B).topk(k=topK, dim=1)[0].mean().view(-1)\n",
    "        else:\n",
    "            res = pA.PROB(A, B).topk(k=B.shape[0], dim=1)[0].mean().view(-1) / pA.PROB(B,B).topk(k=B.shape[0], dim=1)[0].mean().view(-1)\n",
    "        outputs.append(res)\n",
    "    matrix_data += [torch.cat(outputs, dim=-1).view(1,-1)]\n",
    "matrix_data = torch.cat(matrix_data, dim=0)\n",
    "\n",
    "matrix_data = matrix_data.numpy()\n",
    "matrix_data = pd.DataFrame(matrix_data, columns=c_unique)\n",
    "matrix_data['id'] = c_unique\n",
    "\n",
    "m = {}\n",
    "if NEW == False:\n",
    "    m = torch.load('CommClusters/data/corpora/WomanStats/sim.pt')\n",
    "m[input_path[-10:-4]] = matrix_data\n",
    "torch.save(m,'CommClusters/data/corpora/WomanStats/sim.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running the algorithm for analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CommClusters.mod.dataplot import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class prob(nn.Module):\n",
    "\n",
    "    def __init__(self, sigma):\n",
    "        super(prob,self).__init__()\n",
    "        self.dist = torch.distributions.HalfNormal(sigma)\n",
    "\n",
    "    def p(self, x):\n",
    "        return torch.exp(self.dist.log_prob(x))\n",
    "\n",
    "pi = prob(.3)\n",
    "\n",
    "m = torch.load('CommClusters/data/WomanStats.pt')\n",
    "m.keys()\n",
    "\n",
    "cosM, IDX2, IDX1 = m['cos.x']['struct'],m['cos.x']['index'],m['labels']\n",
    "M1 = torch.FloatTensor([[\n",
    "    pi.p(1.-(cosM[sel([i],IDX1),sel([j],IDX2)]/cosM[sel([j],IDX1),sel([j],IDX2)].unsqueeze(1))).mean()\n",
    "    for j in IDX1]\n",
    "    for i in IDX1])\n",
    "\n",
    "M1.shape\n",
    "dfcos = pd.DataFrame(M1.numpy(), columns=m['labels'])\n",
    "dfcos['Country'] = m['labels']\n",
    "dfcos.to_csv('cosine-matrix.csv', index=False, encoding='utf-8')\n",
    "upprob = torch.distributions.Normal(1,.6)\n",
    "pal = sns.diverging_palette(200,100,center='dark',as_cmap=True)\n",
    "pal = sns.palettes.color_palette('Blues_d',as_cmap=True)\n",
    "sel = (m['labels'] == np.array(['United Kingdom', 'France',\n",
    "                                'United States', 'Mexico',\n",
    "                                'Benin', 'Nigeria',\n",
    "                                'Turkey', 'Syria', 'Iran',\n",
    "                                'China', 'India'\n",
    "                                ]).reshape(-1,1)).sum(axis=0).astype(np.bool)\n",
    "print(sel.shape)\n",
    "d, l = M1[sel],m['labels'][sel]\n",
    "d = d[:,sel]\n",
    "Dnom = (d*torch.eye(len(d))).sum(dim=-1)\n",
    "#d = torch.exp(upprob.log_prob(d))\n",
    "plot_data((d/Dnom).nan_to_num().T.numpy(), l)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and another version for the presentation with Dr. Hudson"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from CommClusters.mod.dataplot import *\n",
    "m = torch.load('CommClusters/data/corpora/WomanStats/sim.pt')\n",
    "\n",
    "data = 'PW(p1)'\n",
    "\n",
    "M1 = torch.FloatTensor(m[data][list(m[data])[:-1]].values.astype(np.float))\n",
    "print(M1.shape)\n",
    "country_list = ['United Kingdom', 'France','United States', 'Mexico','Benin', 'Nigeria','Turkey', 'Syria', 'Iran','China', 'India']\n",
    "# country_list = ['Afghanistan', 'Algeria', 'Austria','Fiji', 'Georgia', 'Guyana', 'Indonesia', 'Philippines', 'Russia','Serbia', 'Togo']\n",
    "\n",
    "# pal = sns.diverging_palette(200,100,center='dark',as_cmap=True)\n",
    "# pal = sns.palettes.color_palette('Blues_d',as_cmap=True)\n",
    "upprob = torch.distributions.Normal(1,.6)\n",
    "\n",
    "sel = (m[data]['id'].values == np.array(country_list).reshape(-1,1)).sum(axis=0).astype(np.bool)\n",
    "print(sel.shape)\n",
    "d, l = M1[sel],m[data]['id'].values[sel]\n",
    "# d = d[:,sel]\n",
    "# Dnom = (d*torch.eye(len(d))).sum(dim=-1)\n",
    "# plot_data_square((d/Dnom).nan_to_num().T.numpy(), l)\n",
    "# d = torch.exp(upprob.log_prob(d))\n",
    "# plot_data_square(d.nan_to_num().T.numpy(), l,metric='cityblock')\n",
    "d = torch.exp(upprob.log_prob(d))\n",
    "plot_data(d.nan_to_num().T.numpy(), l, m[data]['id'].values, metric='cosine')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finer-Grained Ethnographic Clustering\n",
    "\n",
    "$$ P(E_x|E_y) = P_{\\mathcal{N}_{[0,\\infty]}} \\left( cosineError(E_x,E_y) \\bigg| \\mu=0, \\sigma \\right) $$\n",
    "\n",
    "$$ P(A|B) = \\prod_{w'} \\frac{1}{k_{B_{w'}}} \\sum_A P(E_A|E_{B_{w'}}) $$\n",
    "\n",
    "### Creating initial clusters\n",
    "This process is wildly preferable to my previous one. If for no other reason, it allows us to compare across search terms before consolidating data for analysis, and this leads to finer grained results.\n",
    "\n",
    "Because my computer can't calculate down to insanely small probabilities, I included two limiting factors in the code. (1) I only used the top N examples from each cosine comparison. (2) rather than taking the product of probabilities which can lead to erroneous zero values due to my computer's precision, I took the mean of the probabilities for all search terms $w'$. This means that the final calulation is\n",
    "\n",
    "$$ P(A|B) = \\frac{1}{N} \\sum \\left(\\prod_{w'} \\frac{1}{k_{B_{w'}}} \\sum_A P(E_A|E_{B_{w'}}) \\right) $$\n",
    "\n",
    "Which ends up being qualitatively the same as taking the product across $w'$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CommClusters.mod.sim_matrix import *\n",
    "\n",
    "NEW = False\n",
    "\n",
    "# input_path = 'CommClusters/data/corpora/WomanStats/LRW/d_LRW.csv'\n",
    "# input_path = 'CommClusters/data/corpora/WomanStats/M/d_M.csv'\n",
    "input_path = 'CommClusters/data/corpora/WomanStats/PW/d_PW(p3).csv'\n",
    "\n",
    "dfi = pd.read_csv(input_path)\n",
    "print(dfi['var'].unique())\n",
    "cID, vID, vecs = dfi['country'].values, dfi['var'].values, torch.FloatTensor([[np.float(i) for i in j.replace('[', '').replace(']', '').split(', ')] for j in dfi['vec'].values])\n",
    "\n",
    "pA = probFn(.3)\n",
    "\n",
    "# vars = ['wives', 'wife']\n",
    "vars = ['polygamy', 'polygyny', #'polygynous'\n",
    "        ]\n",
    "# vars = vars+['marriages', 'marriage']\n",
    "# vars = dfi['var'].unique().tolist()\n",
    "# vars = ['women']\n",
    "\n",
    "cID, vecs = cID[sel(vars, vID)], vecs[sel(vars,vID)]\n",
    "print(np.unique(cID), vecs.shape)\n",
    "\n",
    "matrix_data = []\n",
    "\n",
    "topK = 5\n",
    "\n",
    "c_unique = np.unique(cID)\n",
    "for country in c_unique:\n",
    "    A = vecs[sel([country], cID)]\n",
    "    outputs = []\n",
    "    for C in c_unique:\n",
    "        B = vecs[sel([C], cID)]\n",
    "\n",
    "        res = None\n",
    "        if B.shape[0] >= topK:\n",
    "            res = pA.PROB(A,B).topk(k=topK, dim=-1)[0].sum(dim=-1).view(1,-1)\n",
    "        else:\n",
    "            res = pA.PROB(A,B).topk(k=B.shape[0], dim=-1)[0].sum(dim=-1).view(1,-1)\n",
    "\n",
    "        # res = pA.PROB(A,B).sum(dim=-1).view(1,-1)\n",
    "\n",
    "        outputs.append(res)\n",
    "    outputs = torch.cat(outputs, dim=0)\n",
    "    outputs = outputs/outputs.sum(dim=0)\n",
    "    matrix_data += [outputs.mean(dim=-1).view(1,-1)]\n",
    "matrix_data = torch.cat(matrix_data, dim=0)\n",
    "\n",
    "matrix_data = matrix_data.numpy()\n",
    "matrix_data = pd.DataFrame(matrix_data, columns=c_unique)\n",
    "matrix_data['id'] = c_unique\n",
    "\n",
    "m = {}\n",
    "if NEW == False:\n",
    "    m = torch.load('CommClusters/data/corpora/WomanStats/sim.pt')\n",
    "m[input_path.split('_')[-1][:-4]+'v2'] = matrix_data\n",
    "torch.save(m,'CommClusters/data/corpora/WomanStats/sim.pt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classifying Tucker Carlson Based on Communication Similarity Btw Groups\n",
    "\n",
    "$$ E_x = BERT(x) \\delta_{w=w'} $$\n",
    "\n",
    "$$ P(E_x|E_y) = \\sum P_{\\mathcal{N}_{\\mathcal{T}[0, \\infty]}} \\left( cosineError(E_x, E_y) \\bigg| \\mu=0, \\sigma \\right) $$\n",
    "\n",
    "$$ P(A|B) = \\frac{1}{k} \\sum \\frac{P(E_A|E_B)}{P(E_B|E_B)} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from CommClusters.mod.sim_matrix import *\n",
    "#preformatted BERT embeddings using RoBERTa\n",
    "m = torch.load('CommClusters/data/CarlsonComm.pt')\n",
    "\n",
    "V = torch.FloatTensor([[np.float(i) for i in v.replace('[','').replace(']','').split(', ')] for v in m['df']['vec'].values])\n",
    "ids,lex = m['df']['id'].values, m['df']['lex'].values\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Message Propagation Through a System by Tracking Concept Similarity within a Network\n",
    "## Who inherited Tupac's \"America\"?\n",
    "\n",
    "(1) $$ E_x = BERT(x) \\delta_{w=w'} $$\n",
    "\n",
    "(2) $$ P(A|B) = \\frac{1}{k_B} \\sum_A P_{\\mathcal{N}_{\\mathcal{T}[0, \\infty]}} \\left( cosineError(E_A, E_B) \\bigg| \\mu=0, \\sigma \\right) $$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CommClusters/data/rap-america.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-61aedc21d6bd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mpi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprobFn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m.3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'CommClusters/data/rap-america.pt'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'df'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mm\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'df'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m'Tupac1'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m'Tupac'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Tupac2'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m'Tupac'\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 579\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    580\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    581\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'CommClusters/data/rap-america.pt'"
     ]
    }
   ],
   "source": [
    "from CommClusters.mod.sim_matrix import *\n",
    "\n",
    "pi = probFn(.3)\n",
    "\n",
    "m = torch.load('CommClusters/data/rap-america.pt')\n",
    "m['df'] = m['df'].replace({'Tupac1': 'Tupac', 'Tupac2':'Tupac'})\n",
    "\n",
    "ids, V = m['df']['id'].values, torch.FloatTensor([[np.float(v) for v in i.replace('[', '').replace(']', '').split(', ')] for i in m['df']['vec'].values])\n",
    "\n",
    "rappers = ids[~sel(['Tupac'], ids)]\n",
    "r = pi.PROB(V[~sel(['Tupac'], ids)], V[sel(['Tupac'], ids)])\n",
    "\n",
    "mR = torch.cat([torch.FloatTensor(sel([artist], rappers)).view(1,-1) for artist in np.unique(rappers)], dim=0)\n",
    "\n",
    "r = (r * mR.unsqueeze(-1)).sum(dim=1)\n",
    "r = r/r.sum(dim=0)\n",
    "\n",
    "\n",
    "# I0 = pi.PROB(V[sel(['Tupac'], ids)],V[sel(['Tupac'], ids)])\n",
    "# I0 = (I0.sum(dim=-1)/I0.sum()).unsqueeze(1)\n",
    "#\n",
    "# pacBEST = I0.view(-1).argsort(descending=True)[:10]\n",
    "# pacWORST = I0.view(-1).argsort(descending=False)[:10]\n",
    "# pacI = torch.cat([pacBEST, pacWORST], dim=-1)\n",
    "#\n",
    "#\n",
    "# I0 = I0[pacI].view(1,-1)\n",
    "# PAC = V[sel(['Tupac'], ids)][pacI]\n",
    "#\n",
    "# # eq (2)\n",
    "# candidates = [rapper for rapper in np.unique(m['df']['id'].values) if rapper != 'Tupac']\n",
    "# resp = [pi.PROB(V[sel([rapper], ids)], PAC) for rapper in candidates]\n",
    "# resp = [(i.sum(dim=0)/i.sum()).view(1,-1) for i in resp]\n",
    "#\n",
    "# # eq (3)\n",
    "# # resp = [i/I0 for i in resp]\n",
    "# # resp = [(i.sum(dim=-1)/i.sum()).view(1,-1) for i in resp]\n",
    "#\n",
    "# resp = torch.cat(resp, dim=0)/I0\n",
    "# resp = resp/resp.sum(dim=-1).unsqueeze(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting the data\n",
    "\n",
    "Because it'll look pretty and illustrate the point, we'll hit this with a ridge-plot!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "TOPHITS = r.topk(10,dim=-1)[1]\n",
    "data = [[artist, TOPHITS[i].view(-1).numpy()] for i,artist in enumerate(np.unique(rappers))]\n",
    "\n",
    "graphs = []\n",
    "for rap,g in data:\n",
    "    dd = pd.DataFrame()\n",
    "    dd['x'] = g\n",
    "    dd['id'] = rap\n",
    "    graphs.append(dd)\n",
    "graphs = pd.concat(graphs, ignore_index=True)\n",
    "\n",
    "pal = sns.cubehelix_palette(len(data), rot=-.25, light=.7)\n",
    "g = sns.FacetGrid(graphs, row='id', hue='id', aspect=15, height=.5, palette=pal)\n",
    "\n",
    "g.map(sns.kdeplot, \"x\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"x\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"x\")\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.fig.subplots_adjust(hspace=-.25)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[])\n",
    "g.despine(bottom=True, left=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting the outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}